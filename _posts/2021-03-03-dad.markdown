---
layout: post
title:  "Deep Adaptive Design: Amortizing Sequential Bayesian Experimental Design"
date:   2021-03-03
categories: papers
external_url: https://arxiv.org/abs/2103.02438
external_site: arxiv.org
authors: Adam Foster, Desi R. Ivanova, Ilyas Malik, Tom Rainforth
published: ICML 2021 (long presentation)
thumbnail: assets/dad.png
tag: paper
---

We introduce Deep Adaptive Design (DAD), a general method for amortizing the cost of performing sequential adaptive experiments using the framework of Bayesian optimal experimental design (BOED). Traditional sequential BOED approaches require substantial computational time at each stage of the experiment. This makes them unsuitable for most real-world applications, where decisions must typically be made quickly. DAD addresses this restriction by learning an amortized design network upfront and then using this to rapidly run (multiple) adaptive experiments at deployment time. This network takes as input the data from previous steps, and outputs the next design using a single forward pass; these design decisions can be made in milliseconds during the live experiment. To train the network, we introduce contrastive information bounds that are suitable objectives for the sequential setting, and propose a customized network architecture that exploits key symmetries. We demonstrate that DAD successfully amortizes the process of experimental design, outperforming alternative strategies on a number of problems. 
